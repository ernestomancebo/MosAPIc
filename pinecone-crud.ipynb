{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinecone CRUD\n",
    "\n",
    "This is a step by step followed by [Manfye Goh](https://towardsdatascience.com/crud-with-pinecone-ee6b6f8b54e8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import pinecone\n",
    "from os import getenv\n",
    "\n",
    "pinecone.init(api_key=getenv('PINECONE_API_KEY'),\n",
    "              environment=getenv('PINECONE_API_REGION'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'table-qa'\n",
    "# pinecone.create_index(index_name,\n",
    "#                       dimension=300,\n",
    "#                       metric=\"cosine\")\n",
    "\n",
    "existing_index = pinecone.Index(index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IndexDescription(name='table-qa', metric='cosine', replicas=1, dimension=768.0, shards=1, pods=1, pod_type='p1', status={'ready': True, 'state': 'Ready'}, metadata_config=None, source_collection='')\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pinecone.describe_index(index_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.1,\n",
       " 'namespaces': {'': {'vector_count': 20000}},\n",
       " 'total_vector_count': 20000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C for CREATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tickets reports\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'ticketno': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010],\n",
    "    'complains': [\n",
    "        'Broken navigation button on the website',\n",
    "        'Incorrect pricing displayed for a product',\n",
    "        'Unable to reset password',\n",
    "        'App crashes on the latest iOS update',\n",
    "        'Payment processing error during checkout',\n",
    "        'Wrong product delivered',\n",
    "        'Delayed response from customer support',\n",
    "        'Excessive delivery time for an order',\n",
    "        'Difficulty in finding a specific product',\n",
    "        'Error in applying a discount coupon'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Pushing it into Pinecone, we need to squash it into a vector using some embeding model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)dc709/.gitattributes: 100%|██████████| 690/690 [00:00<?, ?B/s] \n",
      "Downloading pytorch_model.bin: 100%|██████████| 480M/480M [01:45<00:00, 4.54MB/s] \n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 4.61M/4.61M [00:00<00:00, 6.10MB/s]\n",
      "Downloading (…)mbedding_config.json: 100%|██████████| 164/164 [00:00<?, ?B/s] \n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<?, ?B/s] \n",
      "Downloading (…)8744edc709/README.md: 100%|██████████| 2.15k/2.15k [00:00<?, ?B/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 122/122 [00:00<?, ?B/s] \n",
      "Downloading (…)4edc709/modules.json: 100%|██████████| 248/248 [00:00<?, ?B/s] \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"average_word_embeddings_glove.6B.300d\")\n",
    "\n",
    "df[\"question_vector\"] = df.complains.apply(\n",
    "    lambda x: model.encode(str(x)).tolist())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting an eye on those vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.2649574875831604, -0.17953598499298096, 0....\n",
       "1    [0.10973000526428223, 0.3845505118370056, 0.12...\n",
       "2    [-0.21170000731945038, 0.2875896692276001, -0....\n",
       "3    [-0.008352994918823242, -0.13370579481124878, ...\n",
       "4    [-0.17191250622272491, 0.37106096744537354, 0....\n",
       "Name: question_vector, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['question_vector'].head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the upsert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "def chunks(iterable, batch_size=100):\n",
    "    it = iter(iterable)\n",
    "    chunk = tuple(itertools.islice(it, batch_size))\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "\n",
    "\n",
    "for batch in chunks([(str(t), v) for t, v in zip(df.ticketno, df.question_vector)]):\n",
    "    index.upsert(vectors=batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did anything got in?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R for READ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get them by ID.\n",
    "\n",
    "index.fetch([\"1010\", \"1009\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now using a vector. Isn't it the joke here?\n",
    "query_questions = [\n",
    "    \"navigation button\",\n",
    "]\n",
    "\n",
    "query_vectors = [model.encode(str(question)).tolist()\n",
    "                 for question in query_questions]\n",
    "query_results = index.query(queries=query_vectors,\n",
    "                            top_k=5, include_values=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other ways to query/match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract matches and scores from the results\n",
    "matches = []\n",
    "scores = []\n",
    "for match in query_results['results'][0]['matches']:\n",
    "    matches.append(match['id'])\n",
    "    scores.append(match['score'])\n",
    "\n",
    "# Create DataFrame with only matches and scores\n",
    "matches_df = pd.DataFrame({'id': matches, 'score': scores})\n",
    "\n",
    "# Match the result dataframe to main dataframe\n",
    "df[\"ticketno\"] = df[\"ticketno\"].astype(str)\n",
    "matches_df.merge(df, left_on=\"id\", right_on=\"ticketno\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U for UPDATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.upsert(vectors=batch)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D for DELETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By ID\n",
    "\n",
    "index.delete(ids=[\"id-1\", \"id-2\"], namespace='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort of truncate\n",
    "\n",
    "index.delete(deleteAll='true', namespace=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
